{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de233e0-a3de-472b-b3a4-3939836dc170",
   "metadata": {},
   "source": [
    "# Train U-Net\n",
    "\n",
    "This is very similar code to `11_unet_carvana.ipynb` but we have 2 classes instead of 1.\n",
    "\n",
    "With approximately 400 images in the training set, I trained for 100 epochs and get very good results for face tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aafef6-1f53-47b4-96e3-8af83fc1cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from unetTracker.trackingProject import TrackingProject\n",
    "from unetTracker.dataset import UNetDataset\n",
    "from unetTracker.unet import Unet\n",
    "from unetTracker.coordinatesFromSegmentationMask import CoordinatesFromSegmentationMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca89a04-3bec-4342-9100-0576ee8a3a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /home/kevin/Documents/trackingProjects/mouseTrack\n",
      "Loading /home/kevin/Documents/trackingProjects/mouseTrack/config.yalm\n",
      "{'augmentation_HorizontalFlipProb': 0.0, 'augmentation_RandomBrightnessContrastProb': 0.2, 'augmentation_RandomSizedCropProb': 1.0, 'augmentation_RotateProb': 0.3, 'image_size': [480, 480], 'labeling_ImageEnlargeFactor': 2.0, 'name': 'mouseTrack', 'normalization_values': {'means': [0.3958178758621216, 0.39585205912590027, 0.39564093947410583], 'stds': [0.11448581516742706, 0.11446335166692734, 0.11462123692035675]}, 'object_colors': [(0.0, 0.0, 255.0), (255.0, 0.0, 0.0), (255.0, 255.0, 0.0), (240.0, 255.0, 255.0)], 'objects': ['snout', 'earL', 'earR', 'tail'], 'target_radius': 5}\n"
     ]
    }
   ],
   "source": [
    "project = TrackingProject(name=\"mouseTrack\",root_folder = \"/home/kevin/Documents/trackingProjects/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf836a27-2efd-4e4f-b117-c7055cec81fd",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b7b231b-ee84-4204-afb5-4f486a164beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE=1e-4\n",
    "DEVICE = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")) \n",
    "BATCH_SIZE=2\n",
    "NUM_EPOCHS = 40\n",
    "NUM_WORKERS = 4\n",
    "OUTPUT_CHANNELS = len(project.object_list)\n",
    "IMAGE_HEIGHT = project.image_size[0]\n",
    "IMAGE_WIDTH = project.image_size[1]\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = True\n",
    "TRAIN_IMAGE_DIR = os.path.join(project.dataset_dir,\"train_images\")\n",
    "TRAIN_MASK_DIR =  os.path.join(project.dataset_dir,\"train_masks\")\n",
    "TRAIN_COORDINATE_DIR = os.path.join(project.dataset_dir,\"train_coordinates\")\n",
    "VAL_IMAGE_DIR = os.path.join(project.dataset_dir,\"val_images\")\n",
    "VAL_MASK_DIR =  os.path.join(project.dataset_dir,\"val_masks\")\n",
    "VAL_COORDINATE_DIR = os.path.join(project.dataset_dir,\"val_coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a08fc-1cde-466b-9917-086be4b5cf94",
   "metadata": {},
   "source": [
    "## Model, loss, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c7729f9-1692-4a26-97f6-083b8853d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(in_channels=3, out_channels=OUTPUT_CHANNELS).to(DEVICE)\n",
    "if LOAD_MODEL:\n",
    "    project.load_model(model)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss() # not doing sigmoid on the output of the model, so use this, if we had more classes (objects) we would use change out_chan and cross_entropy_loss as loss_fn\n",
    "optimizer= optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ef1c3-3370-4a29-b25f-3b17398bb494",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data augmentation and normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c27d33e-2ef9-4e2d-ae0e-8aceb41df302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trainTransform from /home/kevin/Documents/trackingProjects/mouseTrack/augmentation/trainTransform\n",
      "Loading valTransform from /home/kevin/Documents/trackingProjects/mouseTrack/augmentation/valTransform\n"
     ]
    }
   ],
   "source": [
    "fileName = os.path.join(project.augmentation_dir,\"trainTransform\")\n",
    "print(\"Loading trainTransform from\", fileName)\n",
    "trainTransform=pickle.load(open(fileName,\"rb\" ))\n",
    "\n",
    "fileName = os.path.join(project.augmentation_dir,\"valTransform\")\n",
    "print(\"Loading valTransform from\", fileName)\n",
    "valTransform=pickle.load(open(fileName, \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512b108-1935-45d9-9e9a-de939e710d13",
   "metadata": {},
   "source": [
    "## Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bfa5b17-653a-4db8-9c31-d5c7e72176ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = UNetDataset(TRAIN_IMAGE_DIR, TRAIN_MASK_DIR,TRAIN_COORDINATE_DIR, transform=trainTransform)\n",
    "valDataset = UNetDataset(VAL_IMAGE_DIR, VAL_MASK_DIR,VAL_COORDINATE_DIR, transform=valTransform)\n",
    "trainLoader = DataLoader(trainDataset,shuffle=True,batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,pin_memory=PIN_MEMORY)\n",
    "valLoader = DataLoader(valDataset,shuffle=False,batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,pin_memory = PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab3a05a-01e1-4a9c-b4cb-bb266f1a0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainLoader = DataLoader(trainDataset,\n",
    "                          shuffle=True,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4)\n",
    "valLoader = DataLoader(valDataset,\n",
    "                          shuffle=False,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b334993f-4f13-4c09-a056-66955f3b2e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 480, 480]), torch.Size([2, 4, 480, 480]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, masks, _ = next(iter(trainLoader))\n",
    "imgs.shape, masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b3647-f375-4080-8c9f-0d508bd2ac67",
   "metadata": {},
   "source": [
    "There is a lot of black because half of our pixels are below 0, on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea71b15-19ff-4fe3-b6ef-a0afd0f15e13",
   "metadata": {},
   "source": [
    "# Save and load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0991b991-75e3-497d-ac6e-d2b5fb91fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename = \"my_checkpoint.pth.tar\"):\n",
    "    #print(\"Saving checkpoint\")\n",
    "    torch.save(state,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b0c4c-b328-40bc-a6a3-c09489dd7200",
   "metadata": {},
   "source": [
    "## Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b2bbbef-a284-4fa6-89ad-906bc5712ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model,loader,device):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    num_mask = 0\n",
    "    num_mask_detected = 0\n",
    "    num_detected = 0\n",
    "    sum_distance = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y,c in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            output = torch.sigmoid(model(x))\n",
    "            preds = (output > 0.5).float()\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2*(preds * y).sum() / ((preds+y).sum() + 1e-8)) # work only for binary\n",
    "\n",
    "            # proportion of the mask detected\n",
    "            num_mask += y.sum()\n",
    "            num_mask_detected += preds[y==1.0].sum()\n",
    "            num_detected += preds.sum()\n",
    "\n",
    "            # distance between predicted coordinates and labelled coordinates\n",
    "            output = output.detach().cpu().numpy()\n",
    "            pred_coords = cDetector.detect(output)\n",
    "\n",
    "            sum_distance+= np.nanmean(np.sqrt(((pred_coords[:,:,0:2] - c.numpy())**2).sum(axis=2)))\n",
    "            # we acutally do a mean of the error for the different objects in a batch\n",
    "\n",
    "\n",
    "    print(f\"Accuracy: {num_correct/num_pixels*100:.2f}\")\n",
    "    print(f\"Dice score: {dice_score/len(loader):.2f}\")\n",
    "    print(f\"Mask pixels detected: {num_mask_detected/num_mask*100:.2f}%\")\n",
    "    print(f\"False positives: {(num_detected-num_mask_detected)/num_detected*100:.2f}%\")\n",
    "    print(f\"Mean distance: {sum_distance/len(loader)}\")\n",
    "    a = model.train()\n",
    "\n",
    "cDetector = CoordinatesFromSegmentationMask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b011fe-fd1f-45d4-9c20-cfe078631b01",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438e23e0-a918-4aa4-82a3-04d71cfbf1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader,model,optimizer,loss_fn,scaler,epoch,total_epochs):\n",
    "    \"\"\"\n",
    "    One epoch of training\n",
    "    \"\"\"\n",
    "    loop = tqdm(loader)\n",
    "    for batch_idx, (data,targets,_) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.to(device=DEVICE)\n",
    "        \n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions,targets)\n",
    "            \n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # update tqdm loop\n",
    "        loop.set_postfix_str(\"loss: {:.7f}, epoch: {:d}/{:d}\".format(loss.item(),epoch,total_epochs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b03760e0-5a98-4d58-be63-d4e98dc3c5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time: 2022-11-29 16:06:53.199969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.22it/s, loss: 0.0017195, epoch: 0/40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.58\n",
      "Mask pixels detected: 57.09%\n",
      "False positives: 38.50%\n",
      "Mean distance: 2.3916993321223243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.13it/s, loss: 0.0020861, epoch: 1/40]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.16it/s, loss: 0.0008433, epoch: 2/40]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.17it/s, loss: 0.0007378, epoch: 3/40]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.15it/s, loss: 0.0018001, epoch: 4/40]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.14it/s, loss: 0.0017909, epoch: 5/40]\n",
      "/tmp/ipykernel_75759/3816110341.py:31: RuntimeWarning: Mean of empty slice\n",
      "  sum_distance+= np.nanmean(np.sqrt(((pred_coords[:,:,0:2] - c.numpy())**2).sum(axis=2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.54\n",
      "Mask pixels detected: 43.56%\n",
      "False positives: 23.33%\n",
      "Mean distance: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.08it/s, loss: 0.0006573, epoch: 6/40]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0005509, epoch: 7/40]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.11it/s, loss: 0.0005364, epoch: 8/40]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.13it/s, loss: 0.0016827, epoch: 9/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0005350, epoch: 10/40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.54\n",
      "Mask pixels detected: 44.00%\n",
      "False positives: 24.71%\n",
      "Mean distance: 2.530876711379961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.08it/s, loss: 0.0005486, epoch: 11/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.06it/s, loss: 0.0015821, epoch: 12/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.11it/s, loss: 0.0014793, epoch: 13/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.09it/s, loss: 0.0003773, epoch: 14/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.06it/s, loss: 0.0005145, epoch: 15/40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.41\n",
      "Mask pixels detected: 28.70%\n",
      "False positives: 21.01%\n",
      "Mean distance: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.09it/s, loss: 0.0003958, epoch: 16/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.07it/s, loss: 0.0003296, epoch: 17/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.07it/s, loss: 0.0003713, epoch: 18/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0015171, epoch: 19/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.06it/s, loss: 0.0003095, epoch: 20/40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.38\n",
      "Mask pixels detected: 25.62%\n",
      "False positives: 11.69%\n",
      "Mean distance: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0003311, epoch: 21/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.07it/s, loss: 0.0015360, epoch: 22/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0003295, epoch: 23/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.09it/s, loss: 0.0015572, epoch: 24/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.06it/s, loss: 0.0019684, epoch: 25/40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.48\n",
      "Mask pixels detected: 36.31%\n",
      "False positives: 23.87%\n",
      "Mean distance: 2.6686314062334313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.11it/s, loss: 0.0003207, epoch: 26/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.09it/s, loss: 0.0003385, epoch: 27/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.09it/s, loss: 0.0015859, epoch: 28/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0004159, epoch: 29/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0002575, epoch: 30/40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.63\n",
      "Mask pixels detected: 53.67%\n",
      "False positives: 19.95%\n",
      "Mean distance: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.09it/s, loss: 0.0002976, epoch: 31/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.05it/s, loss: 0.0016484, epoch: 32/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0002711, epoch: 33/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.08it/s, loss: 0.0003169, epoch: 34/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.08it/s, loss: 0.0002406, epoch: 35/40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98\n",
      "Dice score: 0.59\n",
      "Mask pixels detected: 49.15%\n",
      "False positives: 19.23%\n",
      "Mean distance: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.08it/s, loss: 0.0017492, epoch: 36/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.11it/s, loss: 0.0003650, epoch: 37/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.10it/s, loss: 0.0002742, epoch: 38/40]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 55/55 [00:04<00:00, 12.05it/s, loss: 0.0014826, epoch: 39/40]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time: 2022-11-29 16:10:02.451236\n",
      "40 epochs, duration: 0:03:09.251267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "print(\"Starting time:\",startTime)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    train_fn(trainLoader,model,optimizer,loss_fn,scaler,epoch,NUM_EPOCHS)\n",
    "    \n",
    "    if epoch % 5 == 0 :\n",
    "        # save model\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()}\n",
    "        save_checkpoint(checkpoint,filename=os.path.join(project.models_dir,\"my_checkpoint.pth.tar\"))\n",
    "\n",
    "        # check accuracy\n",
    "        check_accuracy(model,valLoader,DEVICE)\n",
    "\n",
    "endTime=datetime.now()\n",
    "print(\"End time:\",endTime)\n",
    "print(\"{} epochs, duration:\".format(NUM_EPOCHS), endTime-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcc7e64d-8b80-42e3-ad71-cea889a30e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model state dict to /home/kevin/Documents/trackingProjects/mouseTrack/models/UNet.pt\n",
      "2022-11-29 16:10:07.832995\n"
     ]
    }
   ],
   "source": [
    "project.save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d4be8-a5c4-4d45-b236-5ce0bdb8033c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
