{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd218d3e-9937-4940-9a09-4d74a9fbcda1",
   "metadata": {},
   "source": [
    "# Adding images for training from a video\n",
    "\n",
    "This notebook is similar to the previous one but the source of the images to label will be a video.\n",
    "\n",
    "As an example here, we will generate the video from a camera and then work from the video.\n",
    "\n",
    "\n",
    "You eventually want to have at least 500 images in your dataset. You can start with 100-200 images and go through all notebooks. You can always add more images and re-train your network. \n",
    "\n",
    "You probably want a minimum of 150 images to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49225de-4b8a-43c1-a16b-2e4776010a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipyevents import Event \n",
    "import threading\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from unetTracker.trackingProject import TrackingProject\n",
    "from unetTracker.dataset import UNetDataset\n",
    "from unetTracker.camera import USBCamera, bgr8_to_jpeg\n",
    "from unetTracker.unetGUI import LabelFromImagesGUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8958448-ee53-4a60-92ef-d049cd78b0ad",
   "metadata": {},
   "source": [
    "Load a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f57b9032-7ed7-4ec1-bda6-9e6a7542633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /home/kevin/Documents/trackingProjects/mouseTrack\n",
      "Loading /home/kevin/Documents/trackingProjects/mouseTrack/config.yalm\n",
      "{'augmentation_HorizontalFlipProb': 0.0, 'augmentation_RandomBrightnessContrastProb': 0.2, 'augmentation_RandomSizedCropProb': 1.0, 'augmentation_RotateProb': 0.3, 'image_size': [480, 480], 'labeling_ImageEnlargeFactor': 2.0, 'name': 'mouseTrack', 'normalization_values': {'means': [0.4181702136993408, 0.4182196259498596, 0.41791409254074097], 'stds': [0.11457645893096924, 0.11454392969608307, 0.11477964371442795]}, 'object_colors': [(0.0, 0.0, 255.0), (255.0, 0.0, 0.0), (255.0, 255.0, 0.0), (240.0, 255.0, 255.0)], 'objects': ['snout', 'earL', 'earR', 'tail'], 'target_radius': 5}\n"
     ]
    }
   ],
   "source": [
    "project = TrackingProject(name=\"mouseTrack\",root_folder = \"/home/kevin/Documents/trackingProjects/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39940d-b495-4448-851f-338181f6d5f7",
   "metadata": {},
   "source": [
    "Create a dataset for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9101ed9a-33e9-4476-a552-97c826933188",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UNetDataset(image_dir=project.image_dir, mask_dir=project.mask_dir, coordinate_dir=project.coordinate_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3865711d-c42b-4db0-948d-baec6dad5dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in the dataset:\",len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3678eb-bd79-44b5-95d1-8de4cb4cb54b",
   "metadata": {},
   "source": [
    "### Creating a video as an example\n",
    "\n",
    "In this notebook, we will label images from a video. \n",
    "\n",
    "In case you don't have a video, you can use a camera to create a small video to work with.\n",
    "\n",
    "**If you already have your video, jump directly to \"Extract Frames from a Video\" section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bcc296e-d968-4690-96a5-702eb54f5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a392f75-34d8-442e-bd8d-a39e5396cb29",
   "metadata": {},
   "source": [
    "Get a camera to create a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239f2eca-de5b-4f0b-842f-ae4f58d33469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera = USBCamera(width=project.image_size[1], height=project.image_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55227825-aa6a-4aa5-b019-9ddb9d327a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame = camera.read()\n",
    "#plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14dabb9-79f8-4d07-aee8-5ddfc8666253",
   "metadata": {},
   "source": [
    "Save a video from the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e45e28-acc0-48a1-9a47-80c4e1025ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame2save=30*10\n",
    "#video_fn = '/tmp/video1.avi'\n",
    "#size=project.image_size[1],project.image_size[0]\n",
    "#video = cv2.VideoWriter(video_fn, cv2.VideoWriter_fourcc(*'MJPG'),30, size)\n",
    "\n",
    "# loop to save the video\n",
    "#for i in range(frame2save):\n",
    "#    frame = camera.read()\n",
    "#    video.write(frame)\n",
    "    \n",
    "#video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580224a-9506-4d74-9736-9f45052a1851",
   "metadata": {},
   "source": [
    "## Extract frames from a video\n",
    "\n",
    "You need to select a directory in which the individual extracted frames will be saved. Here I used a directory within my project directory.\n",
    "\n",
    "Images will be added to any image that is already in the folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4923f1e7-a96e-47b3-bb05-48e3a84a1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kevin/Documents/trackingProjects/mouseTrack/extracted_frames/\n"
     ]
    }
   ],
   "source": [
    "video_fn = \"/ext_drives/d69/data/electro/fjk9263/fjk9263-17112022-1221/output.mp4\"\n",
    "extracted_frame_dir = project.project_dir+\"/extracted_frames/\"\n",
    "print(extracted_frame_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29807bbc-d6e5-4c6a-9a3a-317f0fa234af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames: [   2   49  214  250  260  542  670  988 1032 1395 1573 1605 1629 1639\n",
      " 1786 1813 2135 2184 2366 2469 2534 2694 2763 2851 3120 3209 3225 3338\n",
      " 3439 3832 3872 4170 4277 4320 4487 4516 4699 4706 4856 4917 4976 5136\n",
      " 5630 5632 5664 5734 5887 6333 6591 7104] to /home/kevin/Documents/trackingProjects/mouseTrack/extracted_frames/\n"
     ]
    }
   ],
   "source": [
    "dataset.extract_frames_from_video(video_fn,50,extracted_frame_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a6edf-224e-4839-8414-c207402e9ff5",
   "metadata": {},
   "source": [
    "## Label extracted frames and save to dataset\n",
    "\n",
    "We use a GUI to label the object in the extracted frames.\n",
    "\n",
    "Make sure that your image is shown at maximal size by extending the notebook window. \n",
    "Make sure the label are correctly positioned in the image below.\n",
    "\n",
    "\n",
    "1. In the large image, click on the object selected by the radio button. The label should appear in the picture below. \n",
    "2. If you don't want to save the data from a particular image, click on Next frame.\n",
    "2. Repeat for all your visible objects\n",
    "3. Click on Save labelled frame.\n",
    "4. Repeat for all your images\n",
    "\n",
    "When you click on `Save labelled frame`, the image is remove from the `extract_frame_dir` directory and transfer to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8f021ab-4efd-4aad-a6f2-5cef5bd524fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.labeling_ImageEnlargeFactor = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fc4beb5-a138-4f6a-aac1-08ea37ee886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65ed8439550439f81c3e754427acf7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='Event info'), HBox(children=(Label(value='Objects:'), RadioButtons(layout=Layout(wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<unetTracker.unetGUI.LabelFromImagesGUI at 0x7f42438f70d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelFromImagesGUI(image_dir=extracted_frame_dir,project=project,dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74fcac56-a48b-4c8a-8a36-1efa55ebea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da6837-2852-49f3-8c3f-a68fda611a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
