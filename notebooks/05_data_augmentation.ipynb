{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991a99e3-b732-4a61-a9e4-f636bffeafc2",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "Data augmentation is a process by which we modify our images, and masks when we load them from file using the dataset Object. This process is stochasitc so that the images loaded in each training epoch are slightly different.\n",
    "\n",
    "The main reason one uses data augmentation is to augment the generalization of our model to new images. By changing the images in each training epoch, we force the model to learn more generalizationalbe features instead of learning specific features unique to each labeled image. \n",
    "\n",
    "\n",
    "To implement data augmentation, I used the [Albumentations](https://albumentations.ai/) library. One can create a pipeline to process our images when they are loaded from file. The library can work with image-mask pairs used for segmenation. \n",
    "\n",
    "The normalization of our images (set mean and std of each channel to 0 and 1) can also be performed by the data augmentation pipeline. See the notebook on data normalization.\n",
    "\n",
    "Below I am using 4 transformations. We can set the probability that this transformation is applied using the `p` argument. You can set it in the project configuration file. Alternatively, you can edit the code below.\n",
    "\n",
    "Tips\n",
    "\n",
    "* If you are tracking left/right body parts, you probably don't want to flip your images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2e3b60-67ec-4f01-8c6b-53d1dfdf35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "from unetTracker.trackingProject import TrackingProject\n",
    "from unetTracker.dataset import UNetDataset\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ece471-0bff-4f99-98d0-cb831424883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /home/kevin/Documents/trackingProjects/mouseTrack\n",
      "Loading /home/kevin/Documents/trackingProjects/mouseTrack/config.yalm\n",
      "{'augmentation_HorizontalFlipProb': 0.0, 'augmentation_RandomBrightnessContrastProb': 0.2, 'augmentation_RandomSizedCropProb': 1.0, 'augmentation_RotateProb': 0.3, 'image_size': [480, 480], 'labeling_ImageEnlargeFactor': 2.0, 'name': 'mouseTrack', 'normalization_values': {'means': [0.39945241808891296, 0.3994884490966797, 0.39926499128341675], 'stds': [0.11478571593761444, 0.11476266384124756, 0.11492700129747391]}, 'object_colors': [(0.0, 0.0, 255.0), (255.0, 0.0, 0.0), (255.0, 255.0, 0.0), (240.0, 255.0, 255.0)], 'objects': ['snout', 'earL', 'earR', 'tail'], 'target_radius': 5}\n"
     ]
    }
   ],
   "source": [
    "project = TrackingProject(name=\"mouseTrack\",root_folder = \"/home/kevin/Documents/trackingProjects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bab07e-988e-45bc-9bd8-f6deea622ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose([\n",
      "  RandomSizedCrop(always_apply=False, p=1.0, min_max_height=(430, 480), height=480, width=480, w2h_ratio=1.0, interpolation=1),\n",
      "  HorizontalFlip(always_apply=False, p=0.0),\n",
      "  Rotate(always_apply=False, p=0.3, limit=(-30, 30), interpolation=1, border_mode=0, value=None, mask_value=None, rotate_method='largest_box', crop_border=False),\n",
      "  RandomBrightnessContrast(always_apply=False, p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.39945241808891296, 0.3994884490966797, 0.39926499128341675], std=[0.11478571593761444, 0.11476266384124756, 0.11492700129747391], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n",
      "Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.39945241808891296, 0.3994884490966797, 0.39926499128341675], std=[0.11478571593761444, 0.11476266384124756, 0.11492700129747391], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"
     ]
    }
   ],
   "source": [
    "original_height = project.image_size[0]\n",
    "original_width = project.image_size[1]\n",
    "means = project.normalization_values[\"means\"]\n",
    "stds = project.normalization_values[\"stds\"]\n",
    "\n",
    "trainTransform = A.Compose([   \n",
    "                    A.RandomSizedCrop(min_max_height=(original_height-50, original_height),w2h_ratio=original_width/original_height,height=original_height, width=original_width, p=project.augmentation_RandomSizedCropProb),\n",
    "                    A.HorizontalFlip(p=project.augmentation_HorizontalFlipProb),\n",
    "                    A.Rotate (limit=30,border_mode=cv2.BORDER_CONSTANT,p=project.augmentation_RotateProb),\n",
    "                    A.RandomBrightnessContrast(p=project.augmentation_RandomBrightnessContrastProb),\n",
    "                    A.Normalize(mean=means, std=stds)\n",
    "])\n",
    "\n",
    "valTransform = A.Compose([   \n",
    "                    A.Normalize(mean=means, std=stds)\n",
    "])\n",
    "\n",
    "\n",
    "print(trainTransform)\n",
    "print(valTransform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55810dbe-64c0-4656-8b3b-b4aee449ef17",
   "metadata": {},
   "source": [
    "We can save the transformation in a `augmentation` directory inside our project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c71ae73-2c64-476f-97ba-0728eda43267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kevin/Documents/trackingProjects/mouseTrack/augmentation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.augmentation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02b454ae-8c08-4c54-881e-37e56f8dcd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trainTransform as /home/kevin/Documents/trackingProjects/mouseTrack/augmentation/trainTransform\n"
     ]
    }
   ],
   "source": [
    "fileName = os.path.join(project.augmentation_dir,\"trainTransform\")\n",
    "print(\"Saving trainTransform as\", fileName)\n",
    "pickle.dump( trainTransform, open( fileName, \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a8edfc-8e5d-46cf-976b-4a4645213776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trainTransform as /home/kevin/Documents/trackingProjects/mouseTrack/augmentation/valTransform\n"
     ]
    }
   ],
   "source": [
    "fileName = os.path.join(project.augmentation_dir,\"valTransform\")\n",
    "print(\"Saving trainTransform as\", fileName)\n",
    "pickle.dump( valTransform, open( fileName, \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b372b7c-5aaa-478c-938e-3fa71819f5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
